{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6d5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define the path to your image folder\n",
    "image_folder = \"dataset\"\n",
    "\n",
    "# Initialize empty lists to store the image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Traverse through the folder and its subfolders to collect the image paths and labels\n",
    "for root, dirs, files in os.walk(image_folder):\n",
    "    for file in files:\n",
    "        image_paths.append(os.path.join(root, file))\n",
    "        labels.append(os.path.basename(root))\n",
    "\n",
    "# Load and resize the images\n",
    "image_data = []\n",
    "image_size = (224, 224)  # Adjust the size as per your model's input requirements\n",
    "\n",
    "for path in image_paths:\n",
    "    image = Image.open(path)\n",
    "    image = image.resize(image_size)\n",
    "    image = np.array(image)  # Convert image to numpy array\n",
    "    image_data.append(image)\n",
    "\n",
    "# Convert the labels into one-hot encoded vectors\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Encode labels as integers\n",
    "integer_encoded = label_encoder.fit_transform(labels)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "# One-hot encode integers\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# Create a dataframe combining the image data and labels\n",
    "df = pd.DataFrame({\"image\": image_data, \"label\": onehot_encoded.tolist()})\n",
    "\n",
    "# Split the dataframe into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['image'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the image data\n",
    "X_train_processed = np.stack(X_train.values)\n",
    "X_val_processed = np.stack(X_val.values)\n",
    "\n",
    "# Normalize the pixel values to the range of 0 to 1\n",
    "X_train_processed = X_train_processed / 255.0\n",
    "X_val_processed = X_val_processed / 255.0\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "y_train_processed = np.array(list(y_train))\n",
    "y_val_processed = np.array(list(y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "664dfd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 55, 55, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 55, 55, 32)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 53, 53, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 26, 26, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 612,698\n",
      "Trainable params: 612,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 12s 293ms/step - loss: 0.1902 - accuracy: 0.1808 - val_loss: 0.2581 - val_accuracy: 0.2533\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 0.1339 - accuracy: 0.3208 - val_loss: 0.2390 - val_accuracy: 0.3967\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 11s 290ms/step - loss: 0.1171 - accuracy: 0.4150 - val_loss: 0.1819 - val_accuracy: 0.4333\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.1064 - accuracy: 0.4608 - val_loss: 0.1637 - val_accuracy: 0.4300\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 11s 299ms/step - loss: 0.1002 - accuracy: 0.4817 - val_loss: 0.1526 - val_accuracy: 0.4967\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0956 - accuracy: 0.5017 - val_loss: 0.1407 - val_accuracy: 0.4600\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 0.0940 - accuracy: 0.5017 - val_loss: 0.1439 - val_accuracy: 0.4633\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.0897 - accuracy: 0.5392 - val_loss: 0.1337 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 12s 312ms/step - loss: 0.0861 - accuracy: 0.5508 - val_loss: 0.1214 - val_accuracy: 0.5067\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.0832 - accuracy: 0.5617 - val_loss: 0.1153 - val_accuracy: 0.5033\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 0.0812 - accuracy: 0.5900 - val_loss: 0.1121 - val_accuracy: 0.5067\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 0.0789 - accuracy: 0.5825 - val_loss: 0.1130 - val_accuracy: 0.5067\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 11s 291ms/step - loss: 0.0764 - accuracy: 0.5975 - val_loss: 0.1068 - val_accuracy: 0.4667\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 11s 296ms/step - loss: 0.0753 - accuracy: 0.6133 - val_loss: 0.1017 - val_accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0745 - accuracy: 0.6092 - val_loss: 0.1104 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 12s 304ms/step - loss: 0.0709 - accuracy: 0.6250 - val_loss: 0.1006 - val_accuracy: 0.4967\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0707 - accuracy: 0.6333 - val_loss: 0.0994 - val_accuracy: 0.5500\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0671 - accuracy: 0.6617 - val_loss: 0.0971 - val_accuracy: 0.5300\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0643 - accuracy: 0.6675 - val_loss: 0.0947 - val_accuracy: 0.5533\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0618 - accuracy: 0.6867 - val_loss: 0.0955 - val_accuracy: 0.5600\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0615 - accuracy: 0.6808 - val_loss: 0.0976 - val_accuracy: 0.5433\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0614 - accuracy: 0.6708 - val_loss: 0.0986 - val_accuracy: 0.5200\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0590 - accuracy: 0.7042 - val_loss: 0.0957 - val_accuracy: 0.5600\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 11s 299ms/step - loss: 0.0558 - accuracy: 0.7225 - val_loss: 0.0946 - val_accuracy: 0.5500\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 11s 303ms/step - loss: 0.0538 - accuracy: 0.7275 - val_loss: 0.0970 - val_accuracy: 0.5367\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 0.0511 - accuracy: 0.7558 - val_loss: 0.0945 - val_accuracy: 0.5500\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0472 - accuracy: 0.7683 - val_loss: 0.0965 - val_accuracy: 0.5600\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 11s 303ms/step - loss: 0.0476 - accuracy: 0.7650 - val_loss: 0.1032 - val_accuracy: 0.5400\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0452 - accuracy: 0.7875 - val_loss: 0.1026 - val_accuracy: 0.5167\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 11s 300ms/step - loss: 0.0452 - accuracy: 0.7900 - val_loss: 0.0997 - val_accuracy: 0.5467\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 11s 300ms/step - loss: 0.0430 - accuracy: 0.7958 - val_loss: 0.1046 - val_accuracy: 0.5200\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 12s 304ms/step - loss: 0.0386 - accuracy: 0.8275 - val_loss: 0.1049 - val_accuracy: 0.5800\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0369 - accuracy: 0.8458 - val_loss: 0.1081 - val_accuracy: 0.5600\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0345 - accuracy: 0.8517 - val_loss: 0.1192 - val_accuracy: 0.5567\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0366 - accuracy: 0.8367 - val_loss: 0.1077 - val_accuracy: 0.5567\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0338 - accuracy: 0.8500 - val_loss: 0.1110 - val_accuracy: 0.5467\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0310 - accuracy: 0.8667 - val_loss: 0.1139 - val_accuracy: 0.5700\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0284 - accuracy: 0.8917 - val_loss: 0.1176 - val_accuracy: 0.5633\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 11s 294ms/step - loss: 0.0291 - accuracy: 0.8850 - val_loss: 0.1234 - val_accuracy: 0.5533\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 11s 294ms/step - loss: 0.0272 - accuracy: 0.8875 - val_loss: 0.1235 - val_accuracy: 0.5700\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 0.0284 - accuracy: 0.8933 - val_loss: 0.1242 - val_accuracy: 0.5367\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0251 - accuracy: 0.9133 - val_loss: 0.1366 - val_accuracy: 0.5500\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0237 - accuracy: 0.9058 - val_loss: 0.1340 - val_accuracy: 0.5600\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 12s 309ms/step - loss: 0.0245 - accuracy: 0.9100 - val_loss: 0.1311 - val_accuracy: 0.5367\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0222 - accuracy: 0.9225 - val_loss: 0.1298 - val_accuracy: 0.5567\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.0232 - accuracy: 0.9167 - val_loss: 0.1306 - val_accuracy: 0.5533\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.0191 - accuracy: 0.9375 - val_loss: 0.1347 - val_accuracy: 0.5667\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0191 - accuracy: 0.9342 - val_loss: 0.1420 - val_accuracy: 0.5600\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 12s 323ms/step - loss: 0.0207 - accuracy: 0.9233 - val_loss: 0.1351 - val_accuracy: 0.5800\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0186 - accuracy: 0.9350 - val_loss: 0.1427 - val_accuracy: 0.5533\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.0179 - accuracy: 0.9417 - val_loss: 0.1450 - val_accuracy: 0.5500\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 12s 311ms/step - loss: 0.0184 - accuracy: 0.9375 - val_loss: 0.1519 - val_accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 11s 300ms/step - loss: 0.0152 - accuracy: 0.9517 - val_loss: 0.1599 - val_accuracy: 0.5600\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 0.0149 - accuracy: 0.9450 - val_loss: 0.1534 - val_accuracy: 0.5100\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0192 - accuracy: 0.9342 - val_loss: 0.1472 - val_accuracy: 0.5500\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 11s 297ms/step - loss: 0.0145 - accuracy: 0.9525 - val_loss: 0.1597 - val_accuracy: 0.5467\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0152 - accuracy: 0.9517 - val_loss: 0.1571 - val_accuracy: 0.5267\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.0146 - accuracy: 0.9492 - val_loss: 0.1628 - val_accuracy: 0.5733\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 12s 328ms/step - loss: 0.0139 - accuracy: 0.9558 - val_loss: 0.1666 - val_accuracy: 0.5500\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 12s 309ms/step - loss: 0.0136 - accuracy: 0.9583 - val_loss: 0.1635 - val_accuracy: 0.5567\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 12s 311ms/step - loss: 0.0144 - accuracy: 0.9533 - val_loss: 0.1693 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 12s 309ms/step - loss: 0.0159 - accuracy: 0.9492 - val_loss: 0.1674 - val_accuracy: 0.5667\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 0.0135 - accuracy: 0.9583 - val_loss: 0.1716 - val_accuracy: 0.5467\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 11s 293ms/step - loss: 0.0128 - accuracy: 0.9608 - val_loss: 0.1778 - val_accuracy: 0.5667\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0111 - accuracy: 0.9675 - val_loss: 0.1732 - val_accuracy: 0.5500\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0116 - accuracy: 0.9642 - val_loss: 0.1739 - val_accuracy: 0.5400\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 11s 301ms/step - loss: 0.0105 - accuracy: 0.9667 - val_loss: 0.1730 - val_accuracy: 0.5500\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0110 - accuracy: 0.9650 - val_loss: 0.1832 - val_accuracy: 0.5533\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0112 - accuracy: 0.9617 - val_loss: 0.1734 - val_accuracy: 0.5400\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 0.0103 - accuracy: 0.9667 - val_loss: 0.1802 - val_accuracy: 0.5300\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 12s 314ms/step - loss: 0.0086 - accuracy: 0.9767 - val_loss: 0.1856 - val_accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 13s 339ms/step - loss: 0.0112 - accuracy: 0.9608 - val_loss: 0.1994 - val_accuracy: 0.5400\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 13s 332ms/step - loss: 0.0102 - accuracy: 0.9692 - val_loss: 0.1938 - val_accuracy: 0.5467\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 12s 328ms/step - loss: 0.0118 - accuracy: 0.9675 - val_loss: 0.1806 - val_accuracy: 0.5467\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 12s 316ms/step - loss: 0.0090 - accuracy: 0.9725 - val_loss: 0.1889 - val_accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 12s 317ms/step - loss: 0.0085 - accuracy: 0.9733 - val_loss: 0.1865 - val_accuracy: 0.5533\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0095 - accuracy: 0.9717 - val_loss: 0.1906 - val_accuracy: 0.5467\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 12s 318ms/step - loss: 0.0096 - accuracy: 0.9725 - val_loss: 0.1854 - val_accuracy: 0.5533\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 12s 329ms/step - loss: 0.0085 - accuracy: 0.9742 - val_loss: 0.1929 - val_accuracy: 0.5533\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 0.0082 - accuracy: 0.9692 - val_loss: 0.1962 - val_accuracy: 0.5433\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 12s 321ms/step - loss: 0.0083 - accuracy: 0.9792 - val_loss: 0.2015 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 12s 324ms/step - loss: 0.0097 - accuracy: 0.9683 - val_loss: 0.1932 - val_accuracy: 0.5633\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 11s 299ms/step - loss: 0.0096 - accuracy: 0.9650 - val_loss: 0.2008 - val_accuracy: 0.5667\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 12s 314ms/step - loss: 0.0077 - accuracy: 0.9717 - val_loss: 0.2001 - val_accuracy: 0.5467\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 0.0081 - accuracy: 0.9758 - val_loss: 0.2125 - val_accuracy: 0.5400\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 12s 325ms/step - loss: 0.0081 - accuracy: 0.9692 - val_loss: 0.2035 - val_accuracy: 0.5433\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 0.0070 - accuracy: 0.9758 - val_loss: 0.2028 - val_accuracy: 0.5500\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 12s 318ms/step - loss: 0.0101 - accuracy: 0.9692 - val_loss: 0.2005 - val_accuracy: 0.5300\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 12s 308ms/step - loss: 0.0068 - accuracy: 0.9833 - val_loss: 0.1981 - val_accuracy: 0.5500\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 12s 305ms/step - loss: 0.0076 - accuracy: 0.9767 - val_loss: 0.2002 - val_accuracy: 0.5467\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 12s 306ms/step - loss: 0.0071 - accuracy: 0.9792 - val_loss: 0.2079 - val_accuracy: 0.5533\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 11s 302ms/step - loss: 0.0070 - accuracy: 0.9750 - val_loss: 0.2076 - val_accuracy: 0.5467\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 11s 303ms/step - loss: 0.0069 - accuracy: 0.9800 - val_loss: 0.2103 - val_accuracy: 0.5633\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 11s 303ms/step - loss: 0.0064 - accuracy: 0.9808 - val_loss: 0.2012 - val_accuracy: 0.5400\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 12s 312ms/step - loss: 0.0060 - accuracy: 0.9808 - val_loss: 0.2267 - val_accuracy: 0.5433\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 12s 303ms/step - loss: 0.0068 - accuracy: 0.9792 - val_loss: 0.2134 - val_accuracy: 0.5633\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 11s 296ms/step - loss: 0.0060 - accuracy: 0.9800 - val_loss: 0.2170 - val_accuracy: 0.5467\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 13s 331ms/step - loss: 0.0072 - accuracy: 0.9783 - val_loss: 0.2176 - val_accuracy: 0.5600\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 12s 310ms/step - loss: 0.0071 - accuracy: 0.9783 - val_loss: 0.2135 - val_accuracy: 0.5400\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 11s 303ms/step - loss: 0.0063 - accuracy: 0.9825 - val_loss: 0.2298 - val_accuracy: 0.5433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f9ce453370>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input,Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "#the convolution procedures has three repeated steps for 3 times (conv2D, Maxpooling,Dropout)\n",
    "#1st convolution \n",
    "input_data = Input(shape=(224, 224, 3))\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(input_data) #ReLU takes any value greater than 0 without change; otherwise, the value is 0\n",
    "x = MaxPooling2D(pool_size = (4, 4), strides=(4, 4))(x) # takes the max value of each 4x4 matrix \n",
    "x = Dropout(0.25)(x) #reduces the overfitting and the large complex number in NN \n",
    "#2nd convolution \n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#3rd convolution \n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#fully connected layer formed by feature maps were fabricated by the former convolution\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "output = Dense(26, activation = 'sigmoid')(x) #sigmoid range is [0,1] for reducing the loss value during the training \n",
    "cnn = Model(inputs=input_data, outputs=output)\n",
    "# Compiling the Neural network\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#adam can handle sparse gradients on noisy problems\n",
    "#cross entropy measures the difference between two events or probabilities and it is binary to set 0 withmask and 1 withoutmask\n",
    "cnn.summary()\n",
    "epochs = 100  \n",
    "batch_size = 32\n",
    "cnn.fit(X_train_processed, y_train_processed, validation_data=(X_val_processed, y_val_processed), \n",
    "          batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14cecc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 72ms/step\n",
      "Confusion Matrix:\n",
      "[[53  0  0  2  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0 28  0  0  2  0  3  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [11  0  0  6  0  1  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  4  0  0  3  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  3  6  0  1  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  5  0  0  0  0  2  0  0  0  2  0  0  0  2  0  0  0  0  0  0  0  0  1\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  2  0  0  1  3  0  0  1  1  0  0  0  2  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  8  0  1  0  1  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  2  1  0  1  0  0  0  3  0  0  0  2  2  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  5  0  1  0  0  0  1  0  1  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0]\n",
      " [ 0  0  0  0  6  0  2  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  2  0  0  0  6  0  0  0  3  1  0  0  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  1  1  1  0  3  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  1  2  0  2  2  0  0  0  0  0  0  0  1  1  1  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  1  3  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  2  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0\n",
      "   1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "Accuracy: 0.5466666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        56\n",
      "           1       0.65      0.82      0.73        34\n",
      "           2       1.00      1.00      1.00        19\n",
      "           3       0.40      0.27      0.32        22\n",
      "           4       0.14      0.30      0.19        10\n",
      "           5       0.38      0.50      0.43        12\n",
      "           6       0.14      0.17      0.15        12\n",
      "           7       0.50      1.00      0.67         8\n",
      "           8       0.25      0.10      0.14        10\n",
      "           9       0.62      0.67      0.64        12\n",
      "          10       0.20      0.25      0.22        12\n",
      "          11       0.71      0.50      0.59        10\n",
      "          12       1.00      0.93      0.96        14\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       0.27      0.21      0.24        14\n",
      "          15       0.17      0.12      0.14         8\n",
      "          16       1.00      0.09      0.17        11\n",
      "          17       0.33      0.33      0.33         3\n",
      "          18       0.33      0.14      0.20         7\n",
      "          19       0.33      0.33      0.33         3\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.50      0.25      0.33         4\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.38      0.34      0.33       300\n",
      "weighted avg       0.55      0.55      0.52       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed Mohamed\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ahmed Mohamed\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ahmed Mohamed\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_val_processed)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_val_processed.argmax(axis=1), y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score and recall\n",
    "report = classification_report(y_val_processed.argmax(axis=1), y_pred_classes)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ab968b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import  ConfusionMatrixDisplay,confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "ConfusionMatrixDisplay.from_predictions(y_val_processed.argmax(axis=1), y_pred_classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model,image):\n",
    "    return model.predict(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
